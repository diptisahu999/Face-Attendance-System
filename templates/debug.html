<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Integrated — Smooth Face Recognition</title>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
<style>
  body { background:#f0f2f5; }
  .aspect-ratio-wrapper { position:relative; width:100%; padding-top:56.25%; background:#333; border-radius:12px; overflow:hidden; }
  #video-container { position:absolute; inset:0; width:100%; height:100%; }
  #video-feed { position:absolute; inset:0; width:100%; height:100%; object-fit:cover; transform:scaleX(-1); z-index:1; }

  /* Attendance output style (below the video) */
  #attendanceOutput .attendance-card {
    display: flex;
    gap: 14px;
    align-items: center;
    padding: 16px;
    border-radius: 12px;
    border: 2px solid #32a852;
    background: #eafaf0;
    color: #0b5f2e;
    box-shadow: none;
    font-family: "Arial", sans-serif;
  }
  #attendanceOutput .check {
    min-width: 48px;
    min-height: 48px;
    border-radius: 50%;
    background: #2fb86b;
    display:flex;
    align-items:center;
    justify-content:center;
    color:#fff;
    font-weight:700;
    font-size:20px;
  }
  #attendanceOutput .info .name {
    font-size: 18px;
    font-weight: 700;
    margin-bottom: 2px;
  }
  #attendanceOutput .info .sub {
    font-size: 13px;
    color: #2a6a3f;
  }

  /* overlay hidden so no mirrored text/boxes on the video */
  #canvas-overlay { display:none; }

  #debugPane { margin-top:12px; font-size:14px; }
  #debugJson { white-space:pre-wrap; max-height:160px; overflow:auto; background:#fff; padding:8px; border-radius:6px; border:1px solid #ddd; }

  .controls-row { display:flex; gap:8px; align-items:center; flex-wrap:wrap; margin-top:12px; }
  .api-select { width:250px; }
  @media (orientation: portrait) {
  .aspect-ratio-wrapper {
    /* This creates a 3:4 aspect ratio (taller than it is wide) */
    padding-top: 133.33%; 
  }
}
</style>
</head>
<body class="bg-light">
<div class="container my-5">
  <div class="text-center mb-4">
    <h2>Integrated Face Recognition (Merged Branches)</h2>
    <p class="text-muted">This page has camera selection, back-camera support, smooth capture loop, and attendance UI.</p>
  </div>

  <div class="card p-3 shadow-sm">
    <div class="aspect-ratio-wrapper">
      <div id="video-container">
        <video id="video-feed" autoplay muted playsinline></video>
        <canvas id="canvas-overlay"></canvas>
      </div>
    </div>

    <!-- Attendance card appears here -->
    <div id="attendanceOutput" class="mt-3"></div>

    <div class="controls-row">
      <select id="cameraSelect" class="form-select w-auto" title="Select camera"></select>
      <button id="startButton" class="btn btn-primary">Start Camera</button>
      <button id="stopButton" class="btn btn-outline-secondary">Stop Camera</button>
      <button id="testCurlBtn" class="btn btn-outline-secondary">Test Server (curl)</button>
    </div>

    <div id="status" class="text-center mt-3"></div>

    <!-- <div id="debugPane" class="mt-3">
      <div class="row">
        <div class="col-md-4">
          <ul>
            <li>Target size: <b id="targetSize">640x360</b></li>
            <li>Target FPS: <b id="targetFps">12</b></li>
            <li>Inflight: <b id="inflight">false</b></li>
            <li>Requests sent: <b id="reqSent">0</b></li>
            <li>Requests successful: <b id="reqOk">0</b></li>
            <li>Last response time (ms): <b id="lastRespTime">-</b></li>
            <li>Last faces count: <b id="lastFaceCount">0</b></li>
          </ul>
        </div>
        <div class="col-md-8">
          <div><b>Last response JSON:</b></div>
          <div id="debugJson">— no response yet —</div>
        </div>
      </div>
    </div> -->

  </div>
</div>

<script>
/* ---------------- CONFIG ---------------- */
const TARGET_WIDTH = 640;
const TARGET_HEIGHT = 360;
const TARGET_FPS = 12;
const JPEG_QUALITY = 0.75;

/* ---------------- DOM ---------------- */
const video = document.getElementById('video-feed');
const overlay = document.getElementById('canvas-overlay');
const startButton = document.getElementById('startButton');
const stopButton = document.getElementById('stopButton');
const statusDiv = document.getElementById('status');
const cameraSelect = document.getElementById('cameraSelect');

const elTargetSize = document.getElementById('targetSize');
const elTargetFps = document.getElementById('targetFps');
const elInflight = document.getElementById('inflight');
const elReqSent = document.getElementById('reqSent');
const elReqOk = document.getElementById('reqOk');
const elLastRespTime = document.getElementById('lastRespTime');
const elLastFaceCount = document.getElementById('lastFaceCount');
const elDebugJson = document.getElementById('debugJson');

elTargetSize.textContent = `${TARGET_WIDTH}x${TARGET_HEIGHT}`;
elTargetFps.textContent = TARGET_FPS;

const API_URL = "https://facehrms.techvizor.in/recognize";

/* ---------------- state ---------------- */
let worker;
let inflight = false;
let lastCaptureTime = 0;
let reqSent = 0, reqOk = 0;
let running = false;
let currentStream = null;
let currentFacingMode = 'user';

/* ---------------- attendance output ---------------- */
let attendanceTimeout = null;
function escapeHtml(s) {
  if (!s && s !== 0) return '';
  return String(s)
    .replace(/&/g, '&amp;')
    .replace(/</g, '&lt;')
    .replace(/>/g, '&gt;')
    .replace(/"/g, '&quot;')
    .replace(/'/g, '&#39;');
}
function showAttendanceBelow(name, memberCode, opts = {}) {
    const when = new Date();
    const hh = String(when.getHours()).padStart(2, '0');
    const mm = String(when.getMinutes()).padStart(2, '0');
    const timeText = opts.timeText || `Marked Attendance at ${hh}:${mm}`;

    // Combine name and member code for display
    const displayName = memberCode ? `${name} (${memberCode})` : name;

    const container = document.getElementById('attendanceOutput');
    container.innerHTML = `
        <div class="attendance-card">
            <div class="check">✓</div>
            <div class="info">
                <div class="name">${escapeHtml(displayName)}</div>
                <div class="sub">${escapeHtml(timeText)}</div>
            </div>
        </div>
    `;
    if (attendanceTimeout) clearTimeout(attendanceTimeout);
    attendanceTimeout = setTimeout(() => { container.innerHTML = ''; }, opts.duration || 8000);
}

/* ---------------- worker creation ---------------- */
function createEncoderWorker() {
  const workerCode = `
    self.onmessage = async (ev) => {
      try {
        const bitmap = ev.data.bitmap;
        const meta = ev.data.meta || {};
        const width = meta.width || bitmap.width;
        const height = meta.height || bitmap.height;
        const quality = meta.quality || 0.8;

        const off = new OffscreenCanvas(width, height);
        const ctx = off.getContext('2d');
        ctx.drawImage(bitmap, 0, 0, width, height);
        bitmap.close();

        const blob = await off.convertToBlob({type: 'image/jpeg', quality: quality});
        self.postMessage({ blob });
      } catch (err) {
        self.postMessage({ error: (err && err.message) || String(err) });
      }
    };
  `;
  const blob = new Blob([workerCode], { type: 'application/javascript' });
  return new Worker(URL.createObjectURL(blob));
}

/* ---------------- list cameras ---------------- */
async function listCameras() {
  try {
    const devices = await navigator.mediaDevices.enumerateDevices();
    const videoDevices = devices.filter(d => d.kind === "videoinput");
    cameraSelect.innerHTML = "";
    videoDevices.forEach((device, i) => {
      const option = document.createElement("option");
      option.value = device.deviceId;
      // prefer friendly label when available
      option.text = device.label || `Camera ${i+1}`;
      cameraSelect.appendChild(option);
    });
    if (videoDevices.length === 0) {
      const opt = document.createElement("option");
      opt.text = "No camera found";
      cameraSelect.appendChild(opt);
    }
  } catch (err) {
    console.error("Error listing cameras:", err);
  }
}

/* ---------------- start / stop camera ---------------- */
async function startCamera(deviceId = null) {
  try {
    if (currentStream) {
      currentStream.getTracks().forEach(track => track.stop());
      currentStream = null;
    }
    statusDiv.innerHTML = '<div class="alert alert-info">Starting camera…</div>';

    // Determine the desired aspect ratio based on screen orientation
    const isPortrait = window.innerHeight > window.innerWidth;
    const aspectRatio = isPortrait ? 9 / 16 : 16 / 9;

    const constraints = {
      video: {
        // Use 'aspectRatio' for a natural view instead of fixed width/height
        aspectRatio: { ideal: aspectRatio },
        // You can suggest a width to guide the camera choice
        width: { ideal: 1280 }, 
        frameRate: { ideal: TARGET_FPS }
      },
      audio: false
    };

    if (deviceId) {
        constraints.video.deviceId = { exact: deviceId };
    } else {
        constraints.video.facingMode = currentFacingMode;
    }

    const stream = await navigator.mediaDevices.getUserMedia(constraints);
    currentStream = stream;
    video.srcObject = stream;
    await video.play();

    // Dynamically mirror the video feed only for the front camera
    video.style.transform = (currentFacingMode === 'user' && !deviceId) ? 'scaleX(-1)' : 'scaleX(1)';

    statusDiv.innerHTML = '<div class="alert alert-success">Camera started.</div>';
    startButton.style.display = 'none';
    stopButton.style.display = 'inline-block';
    // ... rest of the function is the same ...
    if (!worker) {
      worker = createEncoderWorker();
      worker.onmessage = onWorkerMessage;
      worker.onerror = (e) => console.error('Worker error', e);
    }
    running = true;
    requestAnimationFrame(loopRAF);

  } catch (err) {
    console.error('camera start failed', err);
    statusDiv.innerHTML = `<div class="alert alert-danger">Camera error: ${err.message || err}</div>`;
  }
}

function stopCamera() {
  if (currentStream) {
    currentStream.getTracks().forEach(t => t.stop());
    currentStream = null;
  }
  running = false;
  startButton.style.display = 'inline-block';
  statusDiv.innerHTML = '<div class="alert alert-secondary">Camera stopped.</div>';
}

/* ---------------- main capture loop ---------------- */
function loopRAF(ts) {
  if (!running) return;
  const interval = 1000 / TARGET_FPS;
  if (ts - lastCaptureTime >= interval) {
    lastCaptureTime = ts;
    captureFrame();
  }
  requestAnimationFrame(loopRAF);
}
async function captureFrame() {
  if (inflight) return;
  if (!video || video.readyState < 2) return; // not enough data
  try {
    const bitmap = await createImageBitmap(video, { resizeWidth: TARGET_WIDTH, resizeHeight: TARGET_HEIGHT });
    inflight = true; updateInflightUI();
    worker.postMessage({ bitmap, meta: { width: TARGET_WIDTH, height: TARGET_HEIGHT, quality: JPEG_QUALITY } }, [bitmap]);
  } catch (err) {
    console.error('createImageBitmap failed', err);
    inflight = false; updateInflightUI();
  }
}

/* ---------------- worker -> main: upload & handle response ---------------- */
async function onWorkerMessage(ev) {
  if (ev.data && ev.data.error) {
    console.error('Worker encoding error:', ev.data.error);
    inflight = false; updateInflightUI();
    return;
  }
  const blob = ev.data && ev.data.blob;
  if (!blob) { inflight = false; updateInflightUI(); return; }

  reqSent++; elReqSent.textContent = reqSent;
  const fd = new FormData(); fd.append('file', blob, 'frame.jpg');

  const start = performance.now();
  let res;
  try {
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), 12000);
    res = await fetch(API_URL, { method: 'POST', body: fd, signal: controller.signal });
    clearTimeout(timeout);
  } catch (err) {
    console.error('Upload failed:', err);
    inflight = false; updateInflightUI();
    return;
  }

  const elapsed = performance.now() - start;
  elLastRespTime.textContent = Math.round(elapsed);

  if (!res.ok) {
    console.error('Server returned non-OK', res.status, await res.text());
    inflight = false; updateInflightUI();
    return;
  }

  let json;
  try { json = await res.json(); }
  catch (err) {
    console.error('Failed to parse JSON response', err);
    inflight = false; updateInflightUI();
    return;
  }

  // update debug JSON
  elDebugJson.textContent = JSON.stringify(json, null, 2);
  reqOk++; elReqOk.textContent = reqOk;

  // handle recognition results (prefer legacy CODE/DATA if present)
  if (json && json.CODE === 1 && json.DATA && json.DATA.name) {
        showAttendanceBelow(json.DATA.name, null); 
    } else if (json.faces && json.faces.length) {
        const best = json.faces.reduce((acc, f) => {
            const score = (typeof f.score !== 'undefined') ? Number(f.score) : -Infinity;
            if ((f.name && f.name.toLowerCase() !== 'unknown') && score > acc.score) {
                return f; 
            }
            return acc;
        }, {name: null, score: -Infinity});

        if (best.name) {
            showAttendanceBelow(best.name, best.member_code);
        }
    }

  // update last faces count (for debug)
  elLastFaceCount.textContent = (json.faces && json.faces.length) ? json.faces.length : 0;

  inflight = false; updateInflightUI();
}

/* ---------------- UI helpers ---------------- */
function updateInflightUI() {
  elInflight.textContent = inflight ? 'true' : 'false';
}

/* ---------------- test curl helper ---------------- */
document.getElementById('testCurlBtn').addEventListener('click', async () => {
  const current = (apiPreset.value === 'custom' && apiCustom.value) ? apiCustom.value : apiPreset.value;
  const sampleCmd = `curl -X POST -F "file=@test.jpg" "${current}"`;
  alert('Run this in your terminal where you have test.jpg:\n\n' + sampleCmd);
});

/* ---------------- wiring and events ---------------- */
startButton.addEventListener('click', () => {
  const selectedDeviceId = cameraSelect.value || null;
  startCamera(selectedDeviceId);
});
stopButton.addEventListener('click', stopCamera);

cameraSelect.addEventListener('change', () => {
  const selectedDeviceId = cameraSelect.value;
  if (running) {
    startCamera(selectedDeviceId);
  }
});

// populate camera list at load
listCameras().then(() => {
  // if there is at least one camera, try to select the back camera label first (if available)
  for (let i = 0; i < cameraSelect.options.length; i++) {
    const label = cameraSelect.options[i].text.toLowerCase();
    if (label.includes('back') || label.includes('rear') || label.includes('environment')) {
      cameraSelect.selectedIndex = i;
      break;
    }
  }
});

</script>
</body>
</html>
